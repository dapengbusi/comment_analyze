{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import jieba\n",
    "from sklearn.model_selection import train_test_split           #划分训练/测试集\n",
    "from sklearn.feature_extraction.text import CountVectorizer    #抽取特征\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import precision_score\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import cycle\n",
    "\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from scipy import interp\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "data_path = '/Users/zhipeng/lesson/python/project/data_ori/'\n",
    "\n",
    "#读取并清洗数据\n",
    "#因为几个文档的编码不大一样，所以兼容了三种编码模式，根据经验，这三种是经常会遇到的\n",
    "def get_txt_data(txt_file):\n",
    "    mostwords=[]\n",
    "    try:\n",
    "        file=open(txt_file,'r',encoding='utf-8')\n",
    "        for line in file.readlines():\n",
    "            curline=line.strip().split(\"\\t\")\n",
    "            mostwords.append(curline)\n",
    "    except:\n",
    "        try:\n",
    "            file=open(txt_file,'r',encoding='gb2312')\n",
    "            for line in file.readlines():\n",
    "                curline=line.strip().split(\"\\t\")\n",
    "                mostwords.append(curline)\n",
    "        except:\n",
    "            try:\n",
    "                file=open(txt_file,'r',encoding='gbk')\n",
    "                for line in file.readlines():\n",
    "                    curline=line.strip().split(\"\\t\")\n",
    "                    mostwords.append(curline)\n",
    "            except:\n",
    "                ''   \n",
    "    return mostwords\n",
    "\n",
    "neg_doc=get_txt_data(r''+ data_path +'neg.txt')\n",
    "pos_doc=get_txt_data(r''+ data_path +'pos.txt')\n",
    "\n",
    "def context_cut(sentence):\n",
    "    words_list=[]\n",
    "    #获取停用词\n",
    "    stop=open(r''+ data_path + 'stopwords.txt','r+',encoding='utf-8')\n",
    "    stopwords=stop.read().split('\\t')\n",
    "    cut_words=list(jieba.cut(sentence))\n",
    "    words_str=\"\"\n",
    "    for word in cut_words:\n",
    "        if not(word in stopwords):\n",
    "            words_list.append(word)\n",
    "        words_str=','.join(words_list)\n",
    "    return words_str,words_list \n",
    "\n",
    "#合并两个数据集，并且打上标签，分成测试集和训练集\n",
    "words=[]\n",
    "word_list=[]\n",
    "for i in neg_doc:\n",
    "    cut_words_str,cut_words_list=context_cut(i[0])\n",
    "    word_list.append((cut_words_str,-1))\n",
    "    words.append(cut_words_list)\n",
    "for j in pos_doc:\n",
    "    cut_words_str2,cut_words_list2=context_cut(j[0])\n",
    "    word_list.append((cut_words_str2,1))\n",
    "    words.append(cut_words_list2)\n",
    "#word_list=[('菜品,质量,好,味道,好,就是,百度,的,问题,总是,用,运力,原因,来,解释,我,也,不,懂,这,是,什么,原因,晚,了,三个,小时,呵呵,厉害,吧,反正,订,了,就,退,不了,只能,干,等', -1),...,...]\n",
    "#将word_list中的值和标签分别赋予给x,y\n",
    "x,y=zip(*word_list)\n",
    "\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=0)\n",
    "\n",
    "def print_data():\n",
    "    print(\"x_train\")\n",
    "    print(x_train)\n",
    "    print(\"x_test\")\n",
    "    print(x_test)\n",
    "    print(\"y_train\")\n",
    "    print(y_train)\n",
    "    print(\"y_test\")\n",
    "    print(y_test)\n",
    "#print_data()\n",
    "\n",
    "def get_df(x_train):\n",
    "    vec = CountVectorizer(max_features=500) #该类会将文本中的词语转换为词频矩阵，矩阵元素a[i][j] 表示j词在i类文本下的词频\n",
    "    tfidf = TfidfTransformer(use_idf = True, norm = 'l2', smooth_idf = True) #该类会统计每个词语的tf-idf权值\n",
    "    tfidf_x_train=tfidf.fit_transform(vec.fit_transform(x_train)) #将文本转为词频矩阵并计算tf-idf\n",
    "    np.set_printoptions(precision = 2)\n",
    "    x_train_weight = tfidf_x_train.toarray()\n",
    "    return x_train_weight\n",
    "\n",
    "def perf_measure(y_actual, y_hat):\n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    TN = 0\n",
    "    FN = 0\n",
    "        \n",
    "    T2 = 0\n",
    "    T0 = 0\n",
    "    Tn2 = 0\n",
    "    for i in range(len(y_hat)): \n",
    "        if y_actual[i]==y_hat[i]==1:\n",
    "           TP += 1\n",
    "        if y_hat[i]==1 and y_actual[i]!=y_hat[i]:\n",
    "           FP += 1\n",
    "        if y_actual[i]==y_hat[i]==-1:\n",
    "           TN += 1\n",
    "        if y_hat[i]==-1 and y_actual[i]!=y_hat[i]:\n",
    "           FN += 1\n",
    "        if y_hat[i] == -2:\n",
    "            Tn2 += 1\n",
    "        if y_hat[i] == 2:\n",
    "            T2 += 1\n",
    "    print(T2, Tn2)\n",
    "    #tn, fp, fn, tp\n",
    "    import prettytable as pt\n",
    "\n",
    "    # tb = pt.PrettyTable( [\"City name\", \"Area\", \"Population\", \"Annual Rainfall\"])\n",
    "    tb = pt.PrettyTable()\n",
    "    y_train_hat = y_hat\n",
    "    y_train = y_actual\n",
    "    #ac = accuracy_score(y_train_hat,y_train)\n",
    "    #pre = precision_score(y_train_hat, y_train)\n",
    "    #recall = recall_score(y_train_hat,y_train)\n",
    "    #f1 = f1_score(y_train_hat,y_train)\n",
    "    #roc = roc_auc_score(y_train_hat,y_train)\n",
    "    ac=pre=recall=f1=roc=0\n",
    "    ac = round(accuracy_score(y_train_hat,y_train),2)\n",
    "    recall = round(recall_score(y_train_hat,y_train),2)\n",
    "    f1 = round(f1_score(y_train_hat,y_train),2)\n",
    "    roc = round(roc_auc_score(y_train_hat,y_train),2)\n",
    "    pre = round(precision_score(y_train_hat, y_train),2)\n",
    "    tb.field_names = [\"TN\", \"FP\", \"FN\", \"TP\", \"precision\", \"accuracy\", \"recall\", \"F1\", \"roc\"]\n",
    "    tb.add_row([TN,FP, FN, TP,pre, ac, recall, f1, roc])\n",
    "    tb.border=False\n",
    "    print(tb)\n",
    "    \n",
    "    \n",
    "    return(TN, FP, FN, TP)\n",
    "    #return(TP, FP, TN, FN)\n",
    "\n",
    "# 分类报告：precision/recall/fi-score/均值/分类个数\n",
    "def report(y_train, y_train_hat):\n",
    "    from sklearn.metrics import classification_report\n",
    "    y_train_hat=[round(x) for x in y_train_hat]\n",
    "    #tn, fp, fn, tp = confusion_matrix(y_train, y_train_hat).ravel()\n",
    "    #target_names = ['-1','1']\n",
    "    print(classification_report(y_train_hat,y_train))\n",
    "    \n",
    "    #print(tn, fp, fn, tp)  # 1 1 1 1\n",
    "    perf_measure(y_train,y_train_hat)\n",
    "    # Compute ROC curve and ROC area for each class\n",
    "    y_test=y_train\n",
    "    y_score=y_train_hat\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    # Compute micro-average ROC curve and ROC area\n",
    "    fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test, y_score)\n",
    "    roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "    plt.figure()\n",
    "    lw = 2\n",
    "    plt.plot(fpr[\"micro\"], tpr[\"micro\"], color='darkorange',\n",
    "             lw=lw, label='ROC curve (area = %0.2f)' % roc_auc[\"micro\"])\n",
    "    plt.plot([-1, 1], [-1, 1], color='navy', lw=lw, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "####\n",
    "print(\"回归模型\")\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lin_reg=LinearRegression()\n",
    "\n",
    "lin_reg.fit(vec.transform(x_train),y_train)\n",
    "\n",
    "#print(vec.transform(x_train))\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "y_test_hat=lin_reg.predict(vec.transform(x_test))\n",
    "y_train_hat=lin_reg.predict(vec.transform(x_train))\n",
    "lin_mse1=mean_squared_error(y_test,y_test_hat)\n",
    "lin_mse2=mean_squared_error(y_train,y_train_hat)\n",
    "\n",
    "#print(\"y_train\")\n",
    "#print(y_train)\n",
    "#print(\"y_train_hat\")\n",
    "#print(y_train_hat)\n",
    "\n",
    "lin_rmse1=np.sqrt(lin_mse1)\n",
    "lin_rmse2=np.sqrt(lin_mse2)\n",
    "#report(y_test, y_test_hat)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##----------4.使用SVM模型进行训练----##\n",
    "from sklearn import svm \n",
    "print(\"----SVM----\")\n",
    "#使用TF-IDF提取特征，使用SVM训练，结果为0.83125\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "classfier = svm.SVC(kernel='linear')\n",
    "classfier.fit(vec.transform(x_train),y_train)\n",
    "#print(classfier.score(vec.transform(x_test),y_test))\n",
    "\n",
    "#print ('训练集:',classfier.score(vec.transform(x_train), y_train))  # 精度\n",
    "#print ('测试集:',classfier.score(vec.transform(x_test), y_test))\n",
    "'''训练集: 0.85234375\n",
    "测试集: 0.83125'''\n",
    "y_train_hat=classfier.predict(vec.transform(x_train))\n",
    "#print ('训练集准确率：',accuracy_score(y_train_hat,y_train))\n",
    "#print ('训练集召回率：',recall_score(y_train_hat,y_train))\n",
    "#print ('F1:',f1_score(y_train_hat,y_train))\n",
    "#print ('ROC值：',roc_auc_score(y_train_hat,y_train))\n",
    "'''训练集准确率： 0.85234375\n",
    "训练集召回率： 0.8585552543453995\n",
    "F1: 0.8506873123716229\n",
    "ROC值： 0.852466476919981'''\n",
    "report(y_train, y_train_hat)\n",
    "\n",
    "###------------\n",
    "print(\"贝叶斯分类器\")\n",
    "classfier = MultinomialNB()\n",
    "classfier.fit(vec.transform(x_train),y_train)\n",
    "y_train_hat=classfier.predict(vec.transform(x_train))\n",
    "report(y_train, y_train_hat)\n",
    "#print('训练集:',classfier.score(vec.transform(x_test),y_test))\n",
    "#print('测试集:',classfier.score(vec.transform(x_train),y_train))\n",
    "\n",
    "\n",
    "###----\n",
    "print(\"逻辑回归\")\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    " \n",
    "tfidf = TfidfVectorizer(strip_accents=None,\n",
    "                        lowercase=False,\n",
    "                        preprocessor=None)\n",
    " \n",
    "param_grid = [{'vect__ngram_range': [(1, 1)],\n",
    "               'clf__penalty': ['l1', 'l2'],\n",
    "               'clf__C': [1.0, 10.0, 100.0]},\n",
    "              {'vect__ngram_range': [(1, 1)],\n",
    "               'vect__use_idf':[False],\n",
    "               'vect__norm':[None],\n",
    "               'clf__penalty': ['l1', 'l2'],\n",
    "               'clf__C': [1.0, 10.0, 100.0]},\n",
    "              ]\n",
    " \n",
    "lr_tfidf = Pipeline([('vect', tfidf),\n",
    "                     ('clf', LogisticRegression(random_state=0))])\n",
    " \n",
    "gs_lr_tfidf = GridSearchCV(lr_tfidf, param_grid,\n",
    "                           scoring='accuracy',\n",
    "                           cv=5,\n",
    "                           verbose=1,\n",
    "                           n_jobs=-1)\n",
    "\n",
    "gs_lr_tfidf.fit(x_train, y_train)\n",
    "y_train_hat=gs_lr_tfidf.predict(x_train)\n",
    "report(y_train, y_train_hat)\n",
    "print('Best parameter set: %s ' % gs_lr_tfidf.best_params_)\n",
    "print('CV Accuracy: %.3f' % gs_lr_tfidf.best_score_)\n",
    "\n",
    "clf = gs_lr_tfidf.best_estimator_\n",
    "print('Test Accuracy: %.3f' % clf.score(x_test, y_test))\n",
    "\n",
    "\n",
    "### 决策树\n",
    "##----------2.决策树-----##\n",
    "#模型效果不好的时候（拟合不足），考虑换个更强大的模型，决策树\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "tree_reg=DecisionTreeRegressor()\n",
    "\n",
    "tree_reg.fit(vec.transform(x_train),y_train)\n",
    "\n",
    "y_test_hat=tree_reg.predict(vec.transform(x_test))\n",
    "y_train_hat=tree_reg.predict(vec.transform(x_train))\n",
    "tree_mse1=mean_squared_error(y_test,y_test_hat)\n",
    "tree_mse2=mean_squared_error(y_train,y_train_hat)\n",
    "tree_rmse1=np.sqrt(tree_mse1)\n",
    "tree_rmse2=np.sqrt(tree_mse2)\n",
    "report(y_test, y_test_hat)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
